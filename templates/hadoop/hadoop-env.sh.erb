# Note: This file is managed by Puppet.

<% if @java_home -%>
export JAVA_HOME=<%= @java_home %>
<% end -%>

# Use YARN for all hadoop commands
export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce

<% if @mapreduce_history_jmxremote_port -%>
# Enable MapReduce JMX connections on port <%= @mapreduce_history_jmxremote_port %>
HADOOP_JOB_HISTORYSERVER_OPTS="-Dcom.sun.management.jmxremote.port=<%= @mapreduce_history_jmxremote_port %> -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false"
<% end -%>

<% if @mapreduce_history_java_opts -%>
# Any additionally supplied HADOOP_JOB_HISTORYSERVER_OPTS
HADOOP_JOB_HISTORYSERVER_OPTS="<%= @mapreduce_history_java_opts %> $HADOOP_JOB_HISTORYSERVER_OPTS"
<% end -%>

<% if @namenode_jmxremote_port -%>
# Enable NameNode JMX connections on port <%= @namenode_jmxremote_port %>
HADOOP_NAMENODE_OPTS="-Dcom.sun.management.jmxremote.port=<%= @namenode_jmxremote_port %> -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false"
<% end -%>
<% if @gelf_logging_enabled -%>
<%# For logging to logstash via gelf, per http://www.paluch.biz/blog/95-logging-hadoop-messages-into-logstash-using-logstash-gelf.html -%>
export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=INFO,RFAS,gelf -Dhdfs.audit.logger=INFO,gelf $HADOOP_NAMENODE_OPTS"
export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=INFO,DRFAS,gelf -Dhdfs.audit.logger=INFO,DRFAAUDIT,gelf $HADOOP_SECONDARYNAMENODE_OPTS"
<% end -%>

<% if @datanode_jmxremote_port -%>
# Enable DateNode JMX connections on port <%= @datanode_jmxremote_port %>
HADOOP_DATANODE_OPTS="-Dcom.sun.management.jmxremote.port=<%= @datanode_jmxremote_port %> -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false"
<% end -%>

<% if @journalnode_jmxremote_port -%>
# Enable JournalNode JMX connections on port <%= @journalnode_jmxremote_port %>
HADOOP_JOURNALNODE_OPTS="-Dcom.sun.management.jmxremote.port=<%= @journalnode_jmxremote_port %> -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false"
<% end -%>

<% if @gelf_logging_enabled -%>
HADOOP_JOBTRACKER_OPTS="-Dhadoop.security.logger=INFO,DRFAS,gelf -Dmapred.audit.logger=INFO,MRAUDIT,gelf -Dmapred.jobsummary.logger=INFO,JSA,gelf $HADOOP_JOBTRACKER_OPTS"
HADOOP_TASKTRACKER_OPTS="-Dhadoop.security.logger=ERROR,console,gelf -Dmapred.audit.logger=ERROR,console,gelf $HADOOP_TASKTRACKER_OPTS"
<%# Upstream sets the default level to ERROR to avoid logging every successful auth -%>
HADOOP_DATANODE_OPTS="-Dhadoop.security.logger=ERROR,DRFAS,gelf $HADOOP_DATANODE_OPTS"

<%# making this conditional avoids modifying /usr/bin/hdfs default of INFO,console -%>
if [ "$YARN_ROOT_LOGGER" = "INFO,RFA" ]; then
  export YARN_ROOT_LOGGER=INFO,RFA,gelf
fi
if [ "$HADOOP_ROOT_LOGGER" = "INFO,RFA" ]; then
  HADOOP_ROOT_LOGGER=INFO,RFA,gelf
fi
export HADOOP_JHS_LOGGER=INFO,JSA,gelf
export HADOOP_MAPRED_ROOT_LOGGER=INFO,console,gelf
export HADOOP_ROOT_SECURITY_LOGGER=INFO,DRFAS,gelf
<% end -%>

<% if @hadoop_heapsize -%>
# Hadoop daemons (NameNode, DataNode) will use this many MB for JVM Heap
HADOOP_HEAPSIZE=<%= @hadoop_heapsize %>
<% end -%>

<% if @hadoop_namenode_opts -%>
# Any additionally supplied HADOOP_NAMENODE_OPTS
HADOOP_NAMENODE_OPTS="$HADOOP_NAMENODE_OPTS <%= @hadoop_namenode_opts %>"
<% end -%>

<% if @hadoop_datanode_opts -%>
# Any additionally supplied HADOOP_DATANODE_OPTS
HADOOP_DATANODE_OPTS="$HADOOP_DATANODE_OPTS <%= @hadoop_datanode_opts %>"
<% end -%>

<% if @hadoop_journalnode_opts -%>
# Any additionally supplied HADOOP_JOURNALNODE_OPTS
HADOOP_JOURNALNODE_OPTS="$HADOOP_JOURNALNODE_OPTS <%= @hadoop_journalnode_opts %>"
<% end -%>
